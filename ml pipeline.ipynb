{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532ce6f0",
   "metadata": {},
   "source": [
    "# 1. Import libraries and load data from database.\n",
    "Import Python libraries\n",
    "\n",
    "Load dataset from database with read_sql_table\n",
    "\n",
    "Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df7ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eabafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///Messages.db')\n",
    "df = pd.read_sql(\"SELECT * FROM Messages\", engine)\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c035c4",
   "metadata": {},
   "source": [
    "# 2. Write a tokenization function to process your text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049076a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    messages\n",
    "       \n",
    "    Returns:\n",
    "    list of words into numbers of same meaning\n",
    "    \"\"\"\n",
    "    # Converting everything to lower case\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # normalization word tokens and remove stop words\n",
    "    normlizer = PorterStemmer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    normlized = [normlizer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return normlized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460eb87",
   "metadata": {},
   "source": [
    "# 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the message column as input and output classification results on the other 36 categories in the dataset. You may find the MultiOutputClassifier helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd01bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bad742",
   "metadata": {},
   "source": [
    "# 4. Train pipeline\n",
    "Split data into train and test sets\n",
    "Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2454e2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x00000194B88BDEE0&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(tokenizer=&lt;function tokenize at 0x00000194B88BDEE0&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(tokenizer=&lt;function tokenize at 0x00000194B88BDEE0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x00000194B88BDEE0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)\n",
    "\n",
    "np.random.seed(13)\n",
    "pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aedb0c7",
   "metadata": {},
   "source": [
    "# 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's classification_report on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab8166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(ArrayL, ArrayP, col_names):\n",
    "    \"\"\"Evalute metrics of the ML pipeline model\n",
    "    \n",
    "    inputs:\n",
    "    ArrayL: array. Array containing the real labels.\n",
    "    ArrayP: array. Array containing predicted labels.\n",
    "    col_names: list of strings. List containing names for each of the ArrayP fields.\n",
    "       \n",
    "    Returns:\n",
    "    data_metrics: Contains accuracy, precision, recall \n",
    "    and f1 score for a given set of ArrayL and ArrayP labels.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Evaluate metrics for each set of labels\n",
    "    for i in range(len(col_names)):\n",
    "        accuracy = accuracy_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        precision = precision_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        recall = recall_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        f1 = f1_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        \n",
    "        metrics.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    # store metrics\n",
    "    metrics = np.array(metrics)\n",
    "    data_metrics = pd.DataFrame(data = metrics, index = col_names, columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "      \n",
    "    return data_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96a19a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.998258   0.999330  0.998393  0.998862\n",
      "request                 0.999027   0.998505  0.995826  0.997164\n",
      "offer                   0.999898   1.000000  0.978947  0.989362\n",
      "aid_related             0.998822   0.998777  0.998411  0.998594\n",
      "medical_help            0.999590   1.000000  0.994888  0.997438\n",
      "medical_products        0.999846   0.998991  0.997984  0.998487\n",
      "search_and_rescue       0.999898   0.998249  0.998249  0.998249\n",
      "security                0.999795   0.997101  0.991354  0.994220\n",
      "military                0.999846   0.996865  0.998430  0.997647\n",
      "water                   1.000000   1.000000  1.000000  1.000000\n",
      "food                    0.999949   0.999545  1.000000  0.999773\n",
      "shelter                 0.999898   1.000000  0.998847  0.999423\n",
      "clothing                0.999898   0.996753  0.996753  0.996753\n",
      "money                   1.000000   1.000000  1.000000  1.000000\n",
      "missing_people          1.000000   1.000000  1.000000  1.000000\n",
      "refugees                0.999795   1.000000  0.993691  0.996835\n",
      "death                   0.999949   0.998891  1.000000  0.999445\n",
      "other_aid               0.999078   0.997670  0.995351  0.996509\n",
      "infrastructure_related  0.999795   1.000000  0.996853  0.998424\n",
      "transport               0.999693   1.000000  0.993348  0.996663\n",
      "buildings               0.999898   1.000000  0.997990  0.998994\n",
      "electricity             0.999949   1.000000  0.997525  0.998761\n",
      "tools                   0.999949   1.000000  0.991803  0.995885\n",
      "hospitals               1.000000   1.000000  1.000000  1.000000\n",
      "shops                   0.999949   1.000000  0.988506  0.994220\n",
      "aid_centers             1.000000   1.000000  1.000000  1.000000\n",
      "other_infrastructure    0.999898   0.998826  0.998826  0.998826\n",
      "weather_related         0.999385   0.998898  0.998898  0.998898\n",
      "floods                  0.999795   1.000000  0.997535  0.998766\n",
      "storm                   0.999795   0.999449  0.998348  0.998898\n",
      "fire                    1.000000   1.000000  1.000000  1.000000\n",
      "earthquake              0.999590   0.996676  0.998890  0.997781\n",
      "cold                    1.000000   1.000000  1.000000  1.000000\n",
      "other_weather           0.999641   0.999025  0.994180  0.996597\n",
      "direct_report           0.998822   0.998674  0.995243  0.996956\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for training set\n",
    "Y_train_pred = pipe.predict(X_train)\n",
    "col_names = list(Y.columns.values)\n",
    "\n",
    "print(eval_metrics(np.array(Y_train), Y_train_pred, col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e38573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.820040   0.837362  0.948460  0.889455\n",
      "request                 0.894575   0.835913  0.482143  0.611552\n",
      "offer                   0.996465   0.000000  0.000000  0.000000\n",
      "aid_related             0.772553   0.740088  0.689810  0.714065\n",
      "medical_help            0.921777   0.575758  0.073218  0.129915\n",
      "medical_products        0.954049   0.775000  0.096573  0.171745\n",
      "search_and_rescue       0.977716   1.000000  0.052288  0.099379\n",
      "security                0.980636   0.250000  0.008065  0.015625\n",
      "military                0.966498   0.608696  0.062780  0.113821\n",
      "water                   0.956201   0.870056  0.370192  0.519393\n",
      "food                    0.936530   0.809145  0.562155  0.663407\n",
      "shelter                 0.937606   0.814545  0.386874  0.524590\n",
      "clothing                0.986476   0.764706  0.134021  0.228070\n",
      "money                   0.979099   0.777778  0.049645  0.093333\n",
      "missing_people          0.987245   0.000000  0.000000  0.000000\n",
      "refugees                0.963424   0.666667  0.024896  0.048000\n",
      "death                   0.959275   0.888889  0.109215  0.194529\n",
      "other_aid               0.868757   0.612245  0.034682  0.065646\n",
      "infrastructure_related  0.932534   0.000000  0.000000  0.000000\n",
      "transport               0.955279   0.722222  0.043478  0.082019\n",
      "buildings               0.952205   0.728814  0.127219  0.216625\n",
      "electricity             0.980636   1.000000  0.015625  0.030769\n",
      "tools                   0.994314   0.000000  0.000000  0.000000\n",
      "hospitals               0.990779   0.000000  0.000000  0.000000\n",
      "shops                   0.994929   0.000000  0.000000  0.000000\n",
      "aid_centers             0.988320   0.000000  0.000000  0.000000\n",
      "other_infrastructure    0.953742   0.000000  0.000000  0.000000\n",
      "weather_related         0.878900   0.855898  0.690270  0.764213\n",
      "floods                  0.952513   0.888502  0.479323  0.622711\n",
      "storm                   0.935300   0.784530  0.452951  0.574317\n",
      "fire                    0.990933   0.500000  0.016949  0.032787\n",
      "earthquake              0.970186   0.896552  0.795107  0.842788\n",
      "cold                    0.979868   0.888889  0.057971  0.108844\n",
      "other_weather           0.946673   0.450000  0.026087  0.049315\n",
      "direct_report           0.852467   0.768233  0.367157  0.496855\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for test set\n",
    "Y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "eval_metrics0 = eval_metrics(np.array(Y_test), Y_test_pred, col_names)\n",
    "print(eval_metrics0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6d9851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   0.764792\n",
       "request                   0.171892\n",
       "offer                     0.004534\n",
       "aid_related               0.417243\n",
       "medical_help              0.080068\n",
       "medical_products          0.050446\n",
       "search_and_rescue         0.027816\n",
       "security                  0.018096\n",
       "military                  0.033041\n",
       "water                     0.064239\n",
       "food                      0.112302\n",
       "shelter                   0.088904\n",
       "clothing                  0.015560\n",
       "money                     0.023206\n",
       "missing_people            0.011449\n",
       "refugees                  0.033618\n",
       "death                     0.045874\n",
       "other_aid                 0.132396\n",
       "infrastructure_related    0.065506\n",
       "transport                 0.046143\n",
       "buildings                 0.051214\n",
       "electricity               0.020440\n",
       "tools                     0.006109\n",
       "hospitals                 0.010873\n",
       "shops                     0.004610\n",
       "aid_centers               0.011872\n",
       "other_infrastructure      0.044222\n",
       "weather_related           0.280352\n",
       "floods                    0.082795\n",
       "storm                     0.093860\n",
       "fire                      0.010834\n",
       "earthquake                0.094321\n",
       "cold                      0.020363\n",
       "other_weather             0.052866\n",
       "direct_report             0.194982\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculation the proportion of each column that have label == 1\n",
    "Y.sum()/len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18296fe0",
   "metadata": {},
   "source": [
    "# 6. Improve your model\n",
    "Use grid search to find better parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d70674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define performance metric for use in grid search scoring object\n",
    "def perform_metric(Y_T, Y_P):\n",
    "    \"\"\"Median F1 score for all classifiers\n",
    "    \n",
    "    inputs:\n",
    "    Y_T: array. Array containing ArrayL labels.\n",
    "    Y_P: array. Array containing ArrayP labels.\n",
    "        \n",
    "    Routputs:\n",
    "    Median F1 score for all  classifiers\n",
    "    \"\"\"\n",
    "    f1_list = []\n",
    "    for i in range(np.shape(Y_P)[1]):\n",
    "        f1 = f1_score(np.array(Y_T)[:, i], Y_P[:, i])\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "    score = np.median(f1_list)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123d2a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5; 1/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 1/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.138 total time= 1.4min\n",
      "[CV 2/5; 1/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 1/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.139 total time= 1.4min\n",
      "[CV 3/5; 1/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 1/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.141 total time= 1.4min\n",
      "[CV 4/5; 1/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 1/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.146 total time= 1.4min\n",
      "[CV 5/5; 1/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 1/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.103 total time= 1.4min\n",
      "[CV 1/5; 2/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 2/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.176 total time=  49.2s\n",
      "[CV 2/5; 2/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 2/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.171 total time=  51.3s\n",
      "[CV 3/5; 2/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 2/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.136 total time=  59.1s\n",
      "[CV 4/5; 2/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 2/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.170 total time= 1.2min\n",
      "[CV 5/5; 2/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 2/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.161 total time=  52.9s\n",
      "[CV 1/5; 3/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 3/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.102 total time= 1.4min\n",
      "[CV 2/5; 3/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 3/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.143 total time= 1.4min\n",
      "[CV 3/5; 3/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 3/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.118 total time= 1.3min\n",
      "[CV 4/5; 3/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 3/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.100 total time= 1.4min\n",
      "[CV 5/5; 3/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 3/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.137 total time=347.4min\n",
      "[CV 1/5; 4/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 4/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.213 total time= 1.2min\n",
      "[CV 2/5; 4/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 2/5; 4/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.197 total time=23.7min\n",
      "[CV 3/5; 4/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 4/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.190 total time= 1.1min\n",
      "[CV 4/5; 4/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 4/5; 4/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.151 total time= 1.0min\n",
      "[CV 5/5; 4/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 4/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.173 total time= 1.1min\n",
      "[CV 1/5; 5/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 5/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.132 total time= 4.2min\n",
      "[CV 2/5; 5/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 5/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.148 total time= 4.1min\n",
      "[CV 3/5; 5/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 5/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.155 total time= 4.1min\n",
      "[CV 4/5; 5/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 5/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.178 total time= 6.9min\n",
      "[CV 5/5; 5/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 5/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.104 total time= 5.3min\n",
      "[CV 1/5; 6/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 6/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.214 total time= 2.3min\n",
      "[CV 2/5; 6/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 6/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.179 total time= 2.3min\n",
      "[CV 3/5; 6/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 6/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.198 total time= 2.2min\n",
      "[CV 4/5; 6/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 6/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.235 total time= 2.3min\n",
      "[CV 5/5; 6/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.193 total time= 2.4min\n",
      "[CV 1/5; 7/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 7/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.135 total time= 4.9min\n",
      "[CV 2/5; 7/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 7/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.169 total time= 8.6min\n",
      "[CV 3/5; 7/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 7/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.117 total time= 4.6min\n",
      "[CV 4/5; 7/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 7/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.151 total time= 3.8min\n",
      "[CV 5/5; 7/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 7/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.121 total time= 3.8min\n",
      "[CV 1/5; 8/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 8/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.171 total time= 2.0min\n",
      "[CV 2/5; 8/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 2/5; 8/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.223 total time= 1.9min\n",
      "[CV 3/5; 8/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 8/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.205 total time= 2.0min\n",
      "[CV 4/5; 8/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 4/5; 8/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.170 total time= 1.9min\n",
      "[CV 5/5; 8/24] START clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 8/24] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.204 total time= 1.8min\n",
      "[CV 1/5; 9/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 9/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.150 total time=  58.5s\n",
      "[CV 2/5; 9/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 9/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.175 total time=  57.8s\n",
      "[CV 3/5; 9/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 9/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.173 total time=  57.2s\n",
      "[CV 4/5; 9/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 9/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.162 total time=  57.4s\n",
      "[CV 5/5; 9/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 9/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.132 total time=  57.6s\n",
      "[CV 1/5; 10/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 10/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.231 total time=  39.9s\n",
      "[CV 2/5; 10/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 10/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.260 total time=  50.5s\n",
      "[CV 3/5; 10/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 10/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.185 total time=  46.8s\n",
      "[CV 4/5; 10/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 10/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.253 total time=  43.3s\n",
      "[CV 5/5; 10/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 10/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.251 total time=  42.1s\n",
      "[CV 1/5; 11/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 11/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.201 total time=  57.6s\n",
      "[CV 2/5; 11/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 11/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.159 total time=  57.3s\n",
      "[CV 3/5; 11/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 11/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.128 total time=  57.2s\n",
      "[CV 4/5; 11/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 11/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.192 total time=10.2min\n",
      "[CV 5/5; 11/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 11/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.164 total time= 1.1min\n",
      "[CV 1/5; 12/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 12/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.188 total time=  46.2s\n",
      "[CV 2/5; 12/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 2/5; 12/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.205 total time=  42.0s\n",
      "[CV 3/5; 12/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 12/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.203 total time=  41.0s\n",
      "[CV 4/5; 12/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.227 total time=  41.4s\n",
      "[CV 5/5; 12/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 12/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.187 total time=  41.0s\n",
      "[CV 1/5; 13/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 13/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.110 total time= 2.3min\n",
      "[CV 2/5; 13/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 13/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.149 total time= 2.4min\n",
      "[CV 3/5; 13/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 13/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.162 total time= 2.5min\n",
      "[CV 4/5; 13/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 13/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.182 total time= 2.4min\n",
      "[CV 5/5; 13/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 13/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.145 total time= 2.5min\n",
      "[CV 1/5; 14/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 14/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.239 total time= 1.7min\n",
      "[CV 2/5; 14/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 14/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.214 total time= 1.8min\n",
      "[CV 3/5; 14/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 14/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.192 total time= 1.4min\n",
      "[CV 4/5; 14/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 14/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.244 total time= 1.4min\n",
      "[CV 5/5; 14/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 14/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.186 total time= 1.4min\n",
      "[CV 1/5; 15/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 15/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.168 total time= 2.1min\n",
      "[CV 2/5; 15/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 15/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.099 total time= 2.1min\n",
      "[CV 3/5; 15/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 15/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.100 total time= 5.3min\n",
      "[CV 4/5; 15/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 15/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.114 total time= 2.3min\n",
      "[CV 5/5; 15/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 15/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.097 total time= 2.5min\n",
      "[CV 1/5; 16/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 16/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.206 total time= 1.5min\n",
      "[CV 2/5; 16/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 2/5; 16/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.220 total time= 1.5min\n",
      "[CV 3/5; 16/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 16/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.216 total time= 1.6min\n",
      "[CV 4/5; 16/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 4/5; 16/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.213 total time= 1.4min\n",
      "[CV 5/5; 16/24] START clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 16/24] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.194 total time= 1.3min\n",
      "[CV 1/5; 17/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 17/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.193 total time=  51.6s\n",
      "[CV 2/5; 17/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 17/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.156 total time=  48.4s\n",
      "[CV 3/5; 17/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 17/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.131 total time=  50.0s\n",
      "[CV 4/5; 17/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 17/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.159 total time=  57.1s\n",
      "[CV 5/5; 17/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 17/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1;, score=0.185 total time=  52.7s\n",
      "[CV 1/5; 18/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 18/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.240 total time=  43.0s\n",
      "[CV 2/5; 18/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 18/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.198 total time=  44.2s\n",
      "[CV 3/5; 18/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 18/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.222 total time=  44.3s\n",
      "[CV 4/5; 18/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 18/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.207 total time=  40.8s\n",
      "[CV 5/5; 18/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 18/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5;, score=0.198 total time=  36.1s\n",
      "[CV 1/5; 19/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 19/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.182 total time=  47.3s\n",
      "[CV 2/5; 19/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 19/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.110 total time=  47.5s\n",
      "[CV 3/5; 19/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 19/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.133 total time=  47.8s\n",
      "[CV 4/5; 19/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 19/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.154 total time=  48.1s\n",
      "[CV 5/5; 19/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 19/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1;, score=0.162 total time=  54.9s\n",
      "[CV 1/5; 20/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 20/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.238 total time=  39.2s\n",
      "[CV 2/5; 20/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 2/5; 20/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.237 total time=  41.5s\n",
      "[CV 3/5; 20/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 20/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.235 total time=  35.2s\n",
      "[CV 4/5; 20/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 4/5; 20/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.244 total time=  41.1s\n",
      "[CV 5/5; 20/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 20/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5;, score=0.190 total time=  40.8s\n",
      "[CV 1/5; 21/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 1/5; 21/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.111 total time= 2.0min\n",
      "[CV 2/5; 21/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 2/5; 21/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.125 total time= 1.8min\n",
      "[CV 3/5; 21/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 3/5; 21/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.124 total time= 1.8min\n",
      "[CV 4/5; 21/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 4/5; 21/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.151 total time= 2.0min\n",
      "[CV 5/5; 21/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1\n",
      "[CV 5/5; 21/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1;, score=0.123 total time= 1.9min\n",
      "[CV 1/5; 22/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 22/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.219 total time= 1.3min\n",
      "[CV 2/5; 22/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 22/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.206 total time= 1.3min\n",
      "[CV 3/5; 22/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 22/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.204 total time= 1.3min\n",
      "[CV 4/5; 22/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 22/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.178 total time= 1.3min\n",
      "[CV 5/5; 22/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 22/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5;, score=0.169 total time= 1.3min\n",
      "[CV 1/5; 23/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 1/5; 23/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.141 total time= 1.9min\n",
      "[CV 2/5; 23/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 2/5; 23/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.141 total time= 1.8min\n",
      "[CV 3/5; 23/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 3/5; 23/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.104 total time= 1.9min\n",
      "[CV 4/5; 23/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 4/5; 23/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.115 total time= 1.9min\n",
      "[CV 5/5; 23/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1\n",
      "[CV 5/5; 23/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1;, score=0.082 total time= 1.7min\n",
      "[CV 1/5; 24/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 1/5; 24/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.202 total time= 1.2min\n",
      "[CV 2/5; 24/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 24/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.177 total time= 1.2min\n",
      "[CV 3/5; 24/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 3/5; 24/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.199 total time= 1.2min\n",
      "[CV 4/5; 24/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 4/5; 24/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.206 total time= 1.2min\n",
      "[CV 5/5; 24/24] START clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5\n",
      "[CV 5/5; 24/24] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5;, score=0.213 total time= 1.2min\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "\n",
    "parameters = {'vect__min_df': [1, 5],\n",
    "              'tfidf__use_idf':[True, False],\n",
    "              'clf__estimator__n_estimators':[10, 25], \n",
    "              'clf__estimator__min_samples_split':[2, 5, 10]}\n",
    "\n",
    "scorer = make_scorer(perform_metric)\n",
    "cv = GridSearchCV(pipe, param_grid = parameters, scoring = scorer, verbose = 10)\n",
    "\n",
    "# Find best parameters\n",
    "np.random.seed(74)\n",
    "T_model = cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b45e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  79.46295342,   54.15748191, 4230.2617157 ,  332.58128495,\n",
       "         289.57834148,  133.44644918,  301.60594077,  111.73908267,\n",
       "          54.75892372,   41.22895889,  166.77928853,   39.08115149,\n",
       "         140.51004877,   86.38558602,  167.7642025 ,   84.17262964,\n",
       "          48.86373706,   38.52895994,   46.11797876,   36.31747661,\n",
       "         109.57557015,   73.51656733,  106.22781258,   67.85794935]),\n",
       " 'std_fit_time': array([6.09273127e-01, 8.84806580e+00, 8.30257882e+03, 5.43139531e+02,\n",
       "        6.42036292e+01, 2.26548970e+00, 1.05161857e+02, 3.71192751e+00,\n",
       "        4.79075535e-01, 3.12951537e+00, 2.19287890e+02, 1.52811519e+00,\n",
       "        3.91387077e+00, 1.02850773e+01, 7.31446192e+01, 5.01785618e+00,\n",
       "        2.74865470e+00, 2.74435041e+00, 2.64018665e+00, 2.25928746e+00,\n",
       "        5.17761681e+00, 7.58070245e-01, 3.70764721e+00, 8.28356362e-01]),\n",
       " 'mean_score_time': array([3.08913784, 3.34390378, 3.65900145, 4.15753527, 5.7895504 ,\n",
       "        4.83844686, 6.04107456, 4.20718102, 3.05294561, 3.39610572,\n",
       "        3.29128375, 3.35466666, 4.5884141 , 4.73340797, 4.44058943,\n",
       "        4.20238724, 3.20525446, 3.25118585, 3.10835772, 3.34228339,\n",
       "        4.23463802, 4.07132568, 4.39441495, 3.87166967]),\n",
       " 'std_score_time': array([0.08650096, 0.52892914, 1.37055919, 0.37256353, 0.6350007 ,\n",
       "        0.09492857, 1.26552773, 0.24091534, 0.04960398, 0.72672937,\n",
       "        0.36368522, 0.46792416, 0.10692796, 2.02231428, 0.3599577 ,\n",
       "        0.4040008 , 0.27173574, 0.35163904, 0.27949221, 0.25971503,\n",
       "        0.19776742, 0.29490165, 0.4715764 , 0.1964784 ]),\n",
       " 'param_clf__estimator__min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__n_estimators': masked_array(data=[10, 10, 10, 10, 25, 25, 25, 25, 10, 10, 10, 10, 25, 25,\n",
       "                    25, 25, 10, 10, 10, 10, 25, 25, 25, 25],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__use_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_vect__min_df': masked_array(data=[1, 5, 1, 5, 1, 5, 1, 5, 1, 5, 1, 5, 1, 5, 1, 5, 1, 5,\n",
       "                    1, 5, 1, 5, 1, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5}],\n",
       " 'split0_test_score': array([0.13793103, 0.17647059, 0.10169492, 0.21276596, 0.1322314 ,\n",
       "        0.21367521, 0.13513514, 0.17105263, 0.15      , 0.23148148,\n",
       "        0.20100503, 0.18823529, 0.10958904, 0.23880597, 0.16756757,\n",
       "        0.20634921, 0.19330855, 0.24      , 0.18229167, 0.23762376,\n",
       "        0.11111111, 0.21890547, 0.14130435, 0.20175439]),\n",
       " 'split1_test_score': array([0.13913043, 0.17085427, 0.14285714, 0.1971831 , 0.14765101,\n",
       "        0.17886179, 0.16949153, 0.22317597, 0.17525773, 0.25974026,\n",
       "        0.15909091, 0.20454545, 0.14876033, 0.21383648, 0.09859155,\n",
       "        0.22      , 0.15625   , 0.19811321, 0.10958904, 0.23684211,\n",
       "        0.125     , 0.20645161, 0.14084507, 0.17741935]),\n",
       " 'split2_test_score': array([0.14084507, 0.13559322, 0.11814346, 0.18972332, 0.15472779,\n",
       "        0.19827586, 0.11715481, 0.20472441, 0.17333333, 0.18461538,\n",
       "        0.128     , 0.20264317, 0.16190476, 0.19178082, 0.1       ,\n",
       "        0.21568627, 0.13114754, 0.22222222, 0.13270142, 0.23484848,\n",
       "        0.12396694, 0.20353982, 0.10434783, 0.1986755 ]),\n",
       " 'split3_test_score': array([0.14583333, 0.17021277, 0.1       , 0.15068493, 0.17777778,\n",
       "        0.23529412, 0.15053763, 0.17021277, 0.16216216, 0.25306122,\n",
       "        0.19178082, 0.22680412, 0.18181818, 0.24390244, 0.11428571,\n",
       "        0.21276596, 0.15942029, 0.20740741, 0.15384615, 0.24427481,\n",
       "        0.15053763, 0.17821782, 0.1147541 , 0.20618557]),\n",
       " 'split4_test_score': array([0.1025641 , 0.16071429, 0.1369863 , 0.17283951, 0.10377358,\n",
       "        0.19298246, 0.12149533, 0.20437956, 0.13157895, 0.25149701,\n",
       "        0.16438356, 0.18705036, 0.14473684, 0.18644068, 0.09655172,\n",
       "        0.19354839, 0.18502203, 0.19753086, 0.16216216, 0.18978102,\n",
       "        0.12264151, 0.16888889, 0.08163265, 0.21307506]),\n",
       " 'mean_test_score': array([0.1332608 , 0.16276903, 0.11993636, 0.18463936, 0.14323231,\n",
       "        0.20381789, 0.13876289, 0.19470907, 0.15846643, 0.23607907,\n",
       "        0.16885206, 0.20185568, 0.14936183, 0.21495328, 0.11539931,\n",
       "        0.20966997, 0.16502968, 0.21305474, 0.14811809, 0.22867404,\n",
       "        0.12665144, 0.19520072, 0.1165768 , 0.19942197]),\n",
       " 'std_test_score': array([0.01558294, 0.01450007, 0.0176039 , 0.02129055, 0.02458891,\n",
       "        0.01928132, 0.01929317, 0.0208033 , 0.01619412, 0.02740659,\n",
       "        0.02585993, 0.01438744, 0.02372495, 0.02348695, 0.02682401,\n",
       "        0.00920243, 0.02216274, 0.01616306, 0.02498016, 0.01970274,\n",
       "        0.01294655, 0.01864816, 0.02269081, 0.01201887]),\n",
       " 'rank_test_score': array([20, 14, 22, 11, 18,  6, 19, 10, 15,  1, 12,  7, 16,  3, 24,  5, 13,\n",
       "         4, 17,  2, 21,  9, 23,  8])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search results\n",
    "T_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e4795aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23607907126298913"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top mean score\n",
    "np.max(T_model.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdbf3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__min_samples_split': 5,\n",
       " 'clf__estimator__n_estimators': 10,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__min_df': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters for top mean score\n",
    "T_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d6bc7",
   "metadata": {},
   "source": [
    "# 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.\n",
    "\n",
    "\n",
    "Since this project focuses on code quality, process, and pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5964be04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.809590   0.840519  0.926314  0.881333\n",
      "request                 0.889811   0.769746  0.513393  0.615961\n",
      "offer                   0.996465   0.000000  0.000000  0.000000\n",
      "aid_related             0.755955   0.709084  0.690556  0.699697\n",
      "medical_help            0.919010   0.469697  0.119461  0.190476\n",
      "medical_products        0.955586   0.690476  0.180685  0.286420\n",
      "search_and_rescue       0.977255   0.608696  0.091503  0.159091\n",
      "security                0.980790   0.333333  0.008065  0.015748\n",
      "military                0.967112   0.578947  0.147982  0.235714\n",
      "water                   0.960350   0.808594  0.497596  0.616071\n",
      "food                    0.938220   0.776632  0.624309  0.692190\n",
      "shelter                 0.936991   0.766562  0.419689  0.542411\n",
      "clothing                0.986937   0.730769  0.195876  0.308943\n",
      "money                   0.979407   0.705882  0.085106  0.151899\n",
      "missing_people          0.987245   0.333333  0.012195  0.023529\n",
      "refugees                0.964039   0.574468  0.112033  0.187500\n",
      "death                   0.966037   0.743243  0.375427  0.498866\n",
      "other_aid               0.867374   0.509091  0.064740  0.114872\n",
      "infrastructure_related  0.931305   0.259259  0.016129  0.030369\n",
      "transport               0.956508   0.637931  0.123746  0.207283\n",
      "buildings               0.951898   0.643678  0.165680  0.263529\n",
      "electricity             0.980636   0.545455  0.093750  0.160000\n",
      "tools                   0.994314   0.000000  0.000000  0.000000\n",
      "hospitals               0.990779   0.500000  0.016667  0.032258\n",
      "shops                   0.994929   0.000000  0.000000  0.000000\n",
      "aid_centers             0.988167   0.000000  0.000000  0.000000\n",
      "other_infrastructure    0.952974   0.000000  0.000000  0.000000\n",
      "weather_related         0.875365   0.822471  0.716216  0.765675\n",
      "floods                  0.952974   0.848765  0.516917  0.642523\n",
      "storm                   0.940833   0.766520  0.555024  0.643848\n",
      "fire                    0.991087   1.000000  0.016949  0.033333\n",
      "earthquake              0.967881   0.893805  0.772171  0.828548\n",
      "cold                    0.981097   0.741935  0.166667  0.272189\n",
      "other_weather           0.944060   0.349206  0.063768  0.107843\n",
      "direct_report           0.845244   0.709440  0.372579  0.488573\n"
     ]
    }
   ],
   "source": [
    "# evaluating metrics for test set\n",
    "tuned_pred_test = T_model.predict(X_test)\n",
    "\n",
    "eval_metrics1 = eval_metrics(np.array(Y_test), tuned_pred_test, col_names)\n",
    "\n",
    "print(eval_metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2069e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.945957</td>\n",
       "      <td>0.580300</td>\n",
       "      <td>0.204490</td>\n",
       "      <td>0.254393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.052247</td>\n",
       "      <td>0.352629</td>\n",
       "      <td>0.271363</td>\n",
       "      <td>0.291971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.772553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.935915</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.023197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.956201</td>\n",
       "      <td>0.740088</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.108844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.980636</td>\n",
       "      <td>0.836638</td>\n",
       "      <td>0.378533</td>\n",
       "      <td>0.521992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.996465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948460</td>\n",
       "      <td>0.889455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  35.000000  35.000000  35.000000  35.000000\n",
       "mean    0.945957   0.580300   0.204490   0.254393\n",
       "std     0.052247   0.352629   0.271363   0.291971\n",
       "min     0.772553   0.000000   0.000000   0.000000\n",
       "25%     0.935915   0.350000   0.011845   0.023197\n",
       "50%     0.956201   0.740088   0.057971   0.108844\n",
       "75%     0.980636   0.836638   0.378533   0.521992\n",
       "max     0.996465   1.000000   0.948460   0.889455"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of 1st model\n",
    "eval_metrics0.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6effc617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.945092</td>\n",
       "      <td>0.561930</td>\n",
       "      <td>0.247463</td>\n",
       "      <td>0.305620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.055489</td>\n",
       "      <td>0.286398</td>\n",
       "      <td>0.268815</td>\n",
       "      <td>0.282367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.755955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.937606</td>\n",
       "      <td>0.409452</td>\n",
       "      <td>0.016808</td>\n",
       "      <td>0.032796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.960350</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.123746</td>\n",
       "      <td>0.207283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.980944</td>\n",
       "      <td>0.766541</td>\n",
       "      <td>0.458643</td>\n",
       "      <td>0.579186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.996465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926314</td>\n",
       "      <td>0.881333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  35.000000  35.000000  35.000000  35.000000\n",
       "mean    0.945092   0.561930   0.247463   0.305620\n",
       "std     0.055489   0.286398   0.268815   0.282367\n",
       "min     0.755955   0.000000   0.000000   0.000000\n",
       "25%     0.937606   0.409452   0.016808   0.032796\n",
       "50%     0.960350   0.643678   0.123746   0.207283\n",
       "75%     0.980944   0.766541   0.458643   0.579186\n",
       "max     0.996465   1.000000   0.926314   0.881333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of tuned model\n",
    "eval_metrics1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb3568",
   "metadata": {},
   "source": [
    "# 8. Try improving your model further. Here are a few ideas:\n",
    "try other machine learning algorithms\n",
    "\n",
    "add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928ffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 1/9] END clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.351 total time= 4.2min\n",
      "[CV 2/5; 1/9] START clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 1/9] END clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.365 total time= 3.7min\n",
      "[CV 3/5; 1/9] START clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 1/9] END clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.336 total time= 3.8min\n",
      "[CV 4/5; 1/9] START clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 1/9] END clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.360 total time= 3.5min\n",
      "[CV 5/5; 1/9] START clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 1/9] END clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.348 total time= 3.8min\n",
      "[CV 1/5; 2/9] START clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 2/9] END clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.162 total time=26.5min\n",
      "[CV 2/5; 2/9] START clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 2/5; 2/9] END clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.130 total time=38.6min\n",
      "[CV 3/5; 2/9] START clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 3/5; 2/9] END clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.123 total time=36.6min\n",
      "[CV 4/5; 2/9] START clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 4/5; 2/9] END clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.128 total time=24.6min\n",
      "[CV 5/5; 2/9] START clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 5/5; 2/9] END clf__estimator__C=1, clf__estimator__degree=2, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.128 total time=22.4min\n",
      "[CV 1/5; 3/9] START clf__estimator__C=1, clf__estimator__degree=3, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n",
      "[CV 1/5; 3/9] END clf__estimator__C=1, clf__estimator__degree=3, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5;, score=0.018 total time=56.8min\n",
      "[CV 2/5; 3/9] START clf__estimator__C=1, clf__estimator__degree=3, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5\n"
     ]
    }
   ],
   "source": [
    "# using SVM instead \n",
    "pipe2 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(SVC()))\n",
    "])\n",
    "\n",
    "parameters2 = {'vect__min_df': [5],\n",
    "              'tfidf__use_idf':[True],\n",
    "              'clf__estimator__kernel': ['poly'], \n",
    "              'clf__estimator__degree': [1, 2, 3],\n",
    "              'clf__estimator__C':[1, 10, 100]}\n",
    "\n",
    "cv2 = GridSearchCV(pipe2, param_grid = parameters2, scoring = scorer, verbose = 10)\n",
    "\n",
    "# Find best parameters\n",
    "np.random.seed(77)\n",
    "T_model2 = cv2.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search results\n",
    "T_model2.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0ae48",
   "metadata": {},
   "source": [
    "median always zero therefore lets evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for test set\n",
    "tuned_pred_test2 = T_model2.predict(X_test)\n",
    "\n",
    "eval_metrics2 = eval_metrics(np.array(Y_test), tuned_pred_test2, col_names)\n",
    "\n",
    "print(eval_metrics2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a455a1f",
   "metadata": {},
   "source": [
    "SVM doesnt work ,we will be using RANDOM FOREST FTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdfed86",
   "metadata": {},
   "source": [
    "# 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle best model\n",
    "pickle.dump(T_model, open('disaster_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1946469",
   "metadata": {},
   "source": [
    "# 10. Use this notebook to complete train.py\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d060c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
